{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhu17072005-cell/Khai_pha_du_lieu_Nhom03/blob/main/RULEBASE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV8Q0gy1sLUJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests\n",
        "!pip install -q bs4\n",
        "!pip install -q html2text\n",
        "!pip install -q chromadb\n",
        "!pip install -q google - generativeai\n",
        "import uuid\n",
        "from datetime import date\n",
        "import hashlib\n",
        "import re\n",
        "import json\n",
        "import html2text\n",
        "h = html2text.HTML2Text()\n",
        "h.body_width = 0\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_3QK2SszHPzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel ('Danh_muc_TTHC_Ho_chieu.xlsx', sheet_name='Sheet1', dtype=str )"
      ],
      "metadata": {
        "id": "Zc0-7Bk9u217"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_URL = \"https://dichvucong.gov.vn/p/home/dvc-chi-tiet-thu-tuc-nganh-doc.html\"\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0 Safari/537.36\"\n",
        "}\n",
        "DATA_FOLDER = '/content/drive/MyDrive/RAG'"
      ],
      "metadata": {
        "id": "7TO6OUZwv02V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  return re.sub(r'\\s+', ' ', text).strip() if text else \"\"\n",
        "\n",
        "def make_chunk(metadata, content, chunk_type, hierarchy, url, title, rows=0, cols=0):\n",
        "    key = f\"{url}{hierarchy}{content[:200]}\"\n",
        "    hash_id = hashlib.sha256(key.encode()).hexdigest()[:20]\n",
        "    chunk = {\n",
        "        \"id\": f\"{hash_id}-{uuid.uuid4().hex[:8]}\",\n",
        "        \"url\": url,\n",
        "        \"title\": title,\n",
        "        \"chunk_type\": chunk_type,\n",
        "        \"hierarchy\": hierarchy,\n",
        "        \"content_text\": content.strip(),\n",
        "        \"metadata\": {\n",
        "            \"source_domain:\": urlparse(url).netloc,\n",
        "            \"tokens\": len(content.split()),\n",
        "            \"has_table\": chunk_type == \"table\",\n",
        "            \"crawl_date\": date.today().strftime(\"%Y-%m-%d\"),\n",
        "            \"procedure_code\": metadata.get(\"procedure_code\", \"\"),\n",
        "            \"category\": metadata.get(\"category\", \"\"),\n",
        "            \"official_annouce\": metadata.get(\"official_annouce\", \"\"),\n",
        "            \"is_entire\": metadata.get(\"is_entire\", \"\"),\n",
        "            \"is_part\": metadata.get(\"is_part\", False)\n",
        "            }\n",
        "        }\n",
        "    if chunk_type == \"table\":\n",
        "        chunk[\"metadata\"].update({\"row_count\": rows, \"col_count\": cols})\n",
        "    return chunk\n",
        "\n",
        "def count_table_cells(table):\n",
        "    rows = table.find_all(\"tr\")\n",
        "    cols = 0\n",
        "    if rows:\n",
        "        for row in rows:\n",
        "            cells = row.find_all([\"th\", \"td\"])\n",
        "            if len(cells) > cols:\n",
        "                cols = len(cells)\n",
        "    return len(rows), cols\n",
        "\n",
        "def crawl_and_chunk(metadata, url, headers):\n",
        "    resp = requests.get(url, headers=headers, timeout=20)\n",
        "    resp.encoding = \"utf-8\"\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "    title = clean_text(soup.h1.get_text()) if soup.h1 else \"Không có tiêu đề\"\n",
        "    chunks = []\n",
        "    hierarchy_stack = []\n",
        "\n",
        "    main = soup.find(\"div\", class_=\"row\")\n",
        "    if main:\n",
        "      main = main.find(\"div\", class_=\"col-sm-8\")\n",
        "    if not main:\n",
        "      main = soup.body\n",
        "\n",
        "    def should_skip(elem):\n",
        "        if not elem.get(\"class\"):\n",
        "          return False\n",
        "        classes = \" \".join(elem.get(\"class\"))\n",
        "        skip_words = [\"breadcrumb\", \"header\", \"footer\", \"navbar\", \"sidebar\", \"related\", \"comment\"]\n",
        "        return any(word in classes for word in skip_words)\n",
        "\n",
        "    def process(elem):\n",
        "        nonlocal hierarchy_stack\n",
        "        if should_skip(elem):\n",
        "          return False\n",
        "\n",
        "        has_processed_child = False\n",
        "\n",
        "        for child in elem.children:\n",
        "          if getattr(child, \"name\", None):\n",
        "            if process(child):\n",
        "              has_processed_child = True\n",
        "#1. Table\n",
        "        if elem.name == \"table\" and not elem.get(\"data-processed\"):\n",
        "          md = h.handle(str(elem)).strip()\n",
        "          if len(md) > 50:\n",
        "            h_text = \">\".join(hierarchy_stack) or title\n",
        "            rows, cols = count_table_cells(elem)\n",
        "            chunks.append(make_chunk(metadata, md, \"table\", h_text, url, title, rows, cols))\n",
        "            elem.attrs[\"data-processed\"] = True\n",
        "          return True\n",
        "\n",
        "#2. List\n",
        "        if elem.name in [\"ul\", \"ol\"]:\n",
        "          items = [clean_text(li.get_text()) for li in elem.find_all(\"li\", recursive=False)]\n",
        "          if items:\n",
        "                content = \"\\n- \" + \"\\n- \".join(items)\n",
        "                h_text = \" > \".join(hierarchy_stack) or title\n",
        "                chunks.append(make_chunk(metadata, content, \"list\", h_text, url, title))\n",
        "          return True\n",
        "\n",
        "#3. Heading\n",
        "        if elem.name in [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]:\n",
        "          level = int(elem.name[1])\n",
        "          text = clean_text(elem.get_text())\n",
        "          if len(hierarchy_stack) >= level:\n",
        "            hierarchy_stack = hierarchy_stack[:level-1]\n",
        "            hierarchy_stack.append(text)\n",
        "          else:\n",
        "            hierarchy_stack.append(text)\n",
        "\n",
        "          h_text = \" > \".join(hierarchy_stack)\n",
        "          chunks.append(make_chunk(metadata, text, \"header\", h_text, url, title))\n",
        "          return True\n",
        "\n",
        "#4. Paragraph\n",
        "        if elem.name in [\"p\", \"div\", \"section\", \"article\"]:\n",
        "          if has_processed_child or elem.get(\"data-processed\") or elem.find(attrs={\"data-processed\": \"true\"}):\n",
        "            return True\n",
        "          text = clean_text(elem.get_text())\n",
        "          if 15 < len(text) < 3000:\n",
        "            h_text = \" > \".join(hierarchy_stack) or title\n",
        "            chunks.append(make_chunk(metadata, text, \"paragraph\", h_text, url, title))\n",
        "            elem[\"data-processed\"] = \"true\"\n",
        "          return True\n",
        "\n",
        "        return has_processed_child\n",
        "    for el in main.descendants:\n",
        "      if getattr(el, \"name\", None):\n",
        "        process(el)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "p0AOdXd2VIVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data = []\n",
        "for idx, row in df.iterrows():\n",
        "  cap_thuc_hien = []\n",
        "  if pd.notna(row.get('Cấp Trung ương')): cap_thuc_hien.append(\"Trung ương\")\n",
        "  if pd.notna(row.get('Cấp Tỉnh')): cap_thuc_hien.append(\"Tỉnh\")\n",
        "  if pd.notna(row.get('Cấp Huyện')): cap_thuc_hien.append(\"Huyện\")\n",
        "  if pd.notna(row.get('Cấp Xã')): cap_thuc_hien.append(\"Xã\")\n",
        "  metadata = {\n",
        "       \"procedure_code\": str(row['Mã TTHC']),\n",
        "                \"procedure_name\": str(row['Tên thủ tục hành chính']),\n",
        "                \"agency\": str(row['Cơ quan thực hiện']),\n",
        "                \"duration\": str(row['Thời hạn giải quyết']),\n",
        "                \"fee\": str(row['Phí, lệ phí']),\n",
        "                \"level\": \", \".join(cap_thuc_hien)\n",
        "  }\n",
        "\n",
        "  id = metadata['procedure_code']\n",
        "  url = BASE_URL + f\"?ma_thu_tuc={id}\"\n",
        "\n",
        "  results = crawl_and_chunk(metadata, url, HEADERS)\n",
        "  data += results\n",
        "\n",
        "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
        "with open(f\"{DATA_FOLDER}/TAI_LIEU_RB.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Đã lưu {len(data)} chunks vào file: TAI_LIEU_RB.json\")"
      ],
      "metadata": {
        "id": "ko70dpjuwmSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "JSON_FILE = '/content/drive/MyDrive/RAG/TAI_LIEU_RB.json'\n",
        "COLLECTION_NAME = \"dichvucong_rag\"\n",
        "EMBEDDING_MODEL = \"BAAI/bge-m3\"\n",
        "\n",
        "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL)\n",
        "\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "collection = client.get_or_create_collection(name=COLLECTION_NAME, embedding_function=embedding_function)"
      ],
      "metadata": {
        "id": "0PGYwwOey43G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(JSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "ids = []\n",
        "documents = []\n",
        "metadatas = []\n",
        "\n",
        "for item in data:\n",
        "    ids.append(item[\"id\"])\n",
        "    documents.append(item[\"content_text\"])\n",
        "    meta = item.get(\"metadata\", {}).copy()\n",
        "\n",
        "    meta.update({\n",
        "         \"url\": item[\"url\"],\n",
        "    \"title\": item[\"title\"],\n",
        "    \"hierarchy\": item[\"hierarchy\"],\n",
        "    \"chunk_type\": item[\"chunk_type\"],\n",
        "    \"domain\": item[\"metadata\"].get(\"source_domain\", \"unknown\"\n",
        "    ),\n",
        "    })\n",
        "\n",
        "    metadatas.append(meta)\n",
        "\n",
        "collection.add(\n",
        "    ids=ids,\n",
        "    documents=documents,\n",
        "    metadatas=metadatas\n",
        ")\n",
        "\n",
        "print(f\"\\nĐã đẩy thành công {len(data)} dòng vào Chroma!\")"
      ],
      "metadata": {
        "id": "QJf5nsQ_zuf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **API KEY**\n",
        "AIzaSyD5alYZZXPaPmf1oraU5zpMx9sJSUx3z-A"
      ],
      "metadata": {
        "id": "F4YnAYQVhT1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"AIzaSyD5alYZZXPaPmf1oraU5zpMx9sJSUx3z-A\"\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "TOTioOx45tHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Chi phí cấp hộ chiếu?\"\n",
        "\n",
        "results = collection.query(\n",
        "    query_texts=[query],\n",
        "    n_results=3,\n",
        "    include=[\"metadatas\", \"documents\", \"distances\"]\n",
        ")\n",
        "context_parts = []\n",
        "for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
        "  context_parts.append(f\"[{meta['hierarchy']}]\\n{doc}\\n(Nguồn:{meta['url']})\")\n",
        "\n",
        "context = \"\\n\\n---\\n\\n\".join(context_parts)"
      ],
      "metadata": {
        "id": "xkG4mki55t-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Bạn là trợ lý hành chính công Việt Nam, trả lời ngắn gọn, chính xác, có dẫn nguồn.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Câu hỏi: {query}\n",
        "\n",
        "Trả lời bằng tiếng Việt, có đánh số nếu là danh sách:\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "  response = model.generate_content(prompt)\n",
        "  print(\"Câu trả lời:\", response.text)\n",
        "except Exception as e:\n",
        "  print(f\"Lỗi: {e}\")"
      ],
      "metadata": {
        "id": "Q4Py9HfS6wUA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}