import streamlit as st
import json
import os
import chromadb
from chromadb.utils import embedding_functions
import google.generativeai as genai

# ==========================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG & B·∫¢O M·∫¨T
# ==========================================
st.set_page_config(
    page_title="Chatbot H·ªô Chi·∫øu Vi·ªát Nam",
    page_icon="üáªüá≥",
    layout="centered"
)

if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("‚ùå Ch∆∞a t√¨m th·∫•y API Key trong Secrets!")
    st.stop()

# ------------------------------------------
@st.cache_resource
def get_safe_model_name():
    try:
        # Li·ªát k√™ model ƒë·ªÉ ki·ªÉm tra t√≠nh kh·∫£ d·ª•ng
        models = [m.name for m in genai.list_models()]
        for m in models:
            if "1.5-flash" in m: return m
        return "gemini-1.5-flash"
    except:
        return "gemini-1.5-flash"

AVAILABLE_MODEL = get_safe_model_name()

# ==========================================
# 2. X·ª¨ L√ù D·ªÆ LI·ªÜU & VECTOR DB
# ==========================================
JSON_FILE = "TAI_LIEU_RB.json"
CHROMA_DB_PATH = "chroma_db_data"

@st.cache_resource
def get_embedding_function():
    # S·ª≠ d·ª•ng model nh·ªè ƒë·ªÉ kh√¥ng t·ªën RAM c·ªßa Streamlit
    return embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="paraphrase-multilingual-MiniLM-L12-v2"
    )

@st.cache_resource
def init_vector_db():
    if not os.path.exists(JSON_FILE):
        return None
    
    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    emb_func = get_embedding_function()
    
    try:
        collection = client.get_collection(name="RAG_procedure", embedding_function=emb_func)
    except:
        collection = client.create_collection(name="RAG_procedure", embedding_function=emb_func)
        with open(JSON_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        collection.add(
            ids=[str(i) for i in range(len(data))],
            documents=[item["content_text"] for item in data],
            metadatas=[
                {"url": item["url"], "title": item["title"], "hierarchy": item["hierarchy"]}
                for item in data
            ]
        )
    return collection

collection = init_vector_db()

# ==========================================
# 3. LOGIC X·ª¨ L√ù CHAT (RAG)
# ==========================================
def get_chatbot_response(user_query):
    # T√¨m ki·∫øm 2 ƒëo·∫°n tin quan tr·ªçng nh·∫•t (gi·∫£m xu·ªëng 2 ƒë·ªÉ ti·∫øt ki·ªám Token)
    results = collection.query(query_texts=[user_query], n_results=2)
    
    context_text = ""
    for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
        context_text += f"\n[Ngu·ªìn: {meta['title']}]\n{doc}\n---\n"

    full_prompt = f"""B·∫°n l√† chuy√™n gia t∆∞ v·∫•n h·ªô chi·∫øu Vi·ªát Nam.
D·ª±a v√†o ng·ªØ c·∫£nh d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi ng·∫Øn g·ªçn, ch√≠nh x√°c.
N·∫øu th√¥ng tin kh√¥ng c√≥, h√£y n√≥i b·∫°n kh√¥ng bi·∫øt.

NG·ªÆ C·∫¢NH:
{context_text}

C√ÇU H·ªéI: {user_query}"""

    model = genai.GenerativeModel(model_name=AVAILABLE_MODEL)
    # C·∫•u h√¨nh gi·∫£m token ƒë·∫ßu ra ƒë·ªÉ ti·∫øt ki·ªám quota
    response = model.generate_content(full_prompt)
    return response.text

# ==========================================
# 4. GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG
# ==========================================
st.title("üáªüá≥ Tr·ª£ l√Ω ·∫£o H·ªô chi·∫øu (T·ªëi ∆∞u Quota)")
st.info(f"Ho·∫°t ƒë·ªông v·ªõi model: `{AVAILABLE_MODEL}`")

if collection is None:
    st.error(f" Kh√¥ng th·∫•y file `{JSON_FILE}`!")
    st.stop()

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ƒêang t√¨m l·ªùi gi·∫£i..."):
            try:
                answer = get_chatbot_response(user_input)
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                if "429" in str(e):
                    st.error("H·ªá th·ªëng ƒëang qu√° t·∫£i (H·∫øt l∆∞·ª£t d√πng mi·ªÖn ph√≠). Vui l√≤ng th·ª≠ l·∫°i sau 1 ph√∫t.")
                else:
                    st.error(f"L·ªói: {str(e)}")

with st.sidebar:
    st.markdown("### H∆∞·ªõng d·∫´n")
    st.write("N·∫øu g·∫∑p l·ªói 429, vui l√≤ng ch·ªù kho·∫£ng 60 gi√¢y tr∆∞·ªõc khi h·ªèi c√¢u ti·∫øp theo.")
    if st.button("X√≥a l·ªãch s·ª≠"):
        st.session_state.messages = []
        st.rerun()
