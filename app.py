import streamlit as st
import json
import os
import chromadb
from chromadb.utils import embedding_functions
import google.generativeai as genai

# ==========================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG
# ==========================================
st.set_page_config(page_title="H·ªó tr·ª£ H·ªô chi·∫øu VN", page_icon="üáªüá≥", layout="wide")

if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("‚ùå Thi·∫øu API Key trong Secrets!")
    st.stop()

# ==========================================
# 2. KH·ªûI T·∫†O D·ªÆ LI·ªÜU (RAG)
# ==========================================
@st.cache_resource
def init_db():
    if not os.path.exists("TAI_LIEU_RB.json"):
        return None
    client = chromadb.PersistentClient(path="chroma_db_data")
    emb_func = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="paraphrase-multilingual-MiniLM-L12-v2"
    )
    try:
        # S·ª≠ d·ª•ng collection m·ªõi ƒë·ªÉ l√†m s·∫°ch d·ªØ li·ªáu
        collection = client.get_or_create_collection(name="passport_stable_v1", embedding_function=emb_func)
        if collection.count() == 0:
            with open("TAI_LIEU_RB.json", "r", encoding="utf-8") as f:
                data = json.load(f)
            documents = [item["content_text"] for item in data]
            metadatas = [{"title": item["title"], "url": item["url"]} for item in data]
            ids = [str(i) for i in range(len(data))]
            collection.add(ids=ids, documents=documents, metadatas=metadatas)
    except Exception as e:
        st.error(f"L·ªói DB: {e}")
        return None
    return collection

collection = init_db()

# ==========================================
# 3. H√ÄM T√åM MODEL KH·∫¢ D·ª§NG (S·ª¨A L·ªñI 404)
# ==========================================
def get_available_model():
    try:
        # Li·ªát k√™ c√°c model m√† Key n√†y c√≥ quy·ªÅn s·ª≠ d·ª•ng
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # ∆Øu ti√™n b·∫£n Flash 1.5 (·ªïn ƒë·ªãnh v√† quota cao nh·∫•t)
        for m in models:
            if "1.5-flash" in m:
                return m
        # N·∫øu kh√¥ng th·∫•y Flash, l·∫•y b·∫•t k·ª≥ model n√†o c√≥ s·∫µn (Pro, v.v.)
        return models[0] if models else "models/gemini-1.5-flash"
    except Exception:
        # N·∫øu l·ªói list_models, tr·∫£ v·ªÅ t√™n ph·ªï bi·∫øn nh·∫•t
        return "models/gemini-1.5-flash"

# ==========================================
# 4. X·ª¨ L√ù AI
# ==========================================
def get_ai_response(user_query):
    if collection is None: return "D·ªØ li·ªáu ch∆∞a s·∫µn s√†ng.", None, None, None

    # L·∫•y 1 ƒëo·∫°n th√¥ng tin li√™n quan nh·∫•t ƒë·ªÉ ti·∫øt ki·ªám Token
    results = collection.query(query_texts=[user_query], n_results=1)
    if not results["documents"][0]:
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p.", None, None, None

    context = results["documents"][0][0]
    meta = results["metadatas"][0][0]
    
    prompt = f"Ng·ªØ c·∫£nh: {context}\n\nC√¢u h·ªèi: {user_query}\nTr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c."

    try:
        model_name = get_available_model()
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)
        return response.text, meta['url'], meta['title'], model_name
    except Exception as e:
        return str(e), None, None, None

# ==========================================
# 5. GIAO DI·ªÜN CHAT
# ==========================================
st.title("üáªüá≥ Tr·ª£ l√Ω ·∫£o H·ªô chi·∫øu")

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi v·ªÅ h·ªô chi·∫øu...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ƒêang k·∫øt n·ªëi..."):
            answer, url, title, m_used = get_ai_response(user_input)
            
            if "429" in answer:
                full_res = "‚ö†Ô∏è H·ªá th·ªëng ƒëang h·∫øt l∆∞·ª£t d√πng mi·ªÖn ph√≠. Vui l√≤ng ch·ªù 60 gi√¢y."
            elif url:
                full_res = f"{answer}\n\n---\n**Ngu·ªìn:** {title}\nüîó [Link D·ªãch v·ª• c√¥ng]({url})"
            else:
                full_res = answer
            
            st.markdown(full_res)
            if m_used: st.caption(f"ƒê√£ s·ª≠ d·ª•ng model: {m_used}")
            st.session_state.messages.append({"role": "assistant", "content": full_res})
