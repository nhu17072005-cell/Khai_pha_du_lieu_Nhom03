import streamlit as st
import json
import os
import chromadb
from chromadb.utils import embedding_functions
import google.generativeai as genai

# ==========================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG
# ==========================================
st.set_page_config(
    page_title="Chatbot H·ªô Chi·∫øu Vi·ªát Nam",
    page_icon="üáªüá≥",
    layout="centered"
)

# L·∫•y API Key t·ª´ Secrets c·ªßa Streamlit Cloud (B·∫£o m·∫≠t)
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    # Key d·ª± ph√≤ng (N·∫øu ch·∫°y local th√¨ ƒëi·ªÅn tr·ª±c ti·∫øp ·ªü ƒë√¢y ho·∫∑c d√πng file secrets.toml)
    api_key = "AIzaSyCzcZwCm4cycmjT2Q1biZNYDfbI5sh9Cr4"

genai.configure(api_key=api_key)

# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n file
JSON_FILE = "TAI_LIEU_RB.json" 
CHROMA_DB_PATH = "chroma_db_data"
COLLECTION_NAME = "RAG_procedure"
GEMINI_MODEL = "gemini-1.5-flash" 

# ==========================================
# 2. X·ª¨ L√ù D·ªÆ LI·ªÜU & EMBEDDING
# ==========================================
@st.cache_resource
def get_embedding_function():
    # S·ª≠ d·ª•ng model ƒëa ng√¥n ng·ªØ nh·∫π ƒë·ªÉ t·ªëi ∆∞u RAM tr√™n Cloud
    return embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="paraphrase-multilingual-MiniLM-L12-v2"
    )

@st.cache_resource
def init_vector_db():
    if not os.path.exists(JSON_FILE):
        return None
    
    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    emb_func = get_embedding_function()
    
    try:
        # Th·ª≠ k·∫øt n·ªëi collection c≈©
        collection = client.get_collection(name=COLLECTION_NAME, embedding_function=emb_func)
    except:
        # N·∫øu ch∆∞a c√≥ th√¨ t·∫°o m·ªõi v√† n·∫°p d·ªØ li·ªáu t·ª´ file JSON
        collection = client.create_collection(name=COLLECTION_NAME, embedding_function=emb_func)
        with open(JSON_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        collection.add(
            ids=[str(i) for i in range(len(data))],
            documents=[item["content_text"] for item in data],
            metadatas=[
                {"url": item["url"], "title": item["title"], "hierarchy": item["hierarchy"]}
                for item in data
            ]
        )
    return collection

# Kh·ªüi t·∫°o database
collection = init_vector_db()

# ==========================================
# 3. GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (UI)
# ==========================================
st.title("üáªüá≥ Tr·ª£ l√Ω ·∫£o Th·ªß t·ª•c H·ªô chi·∫øu")
st.markdown("---")

if collection is None:
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file `{JSON_FILE}`. H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ upload file n√†y l√™n GitHub.")
    st.stop()

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã tin nh·∫Øn c≈©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# H√†m x·ª≠ l√Ω truy v·∫•n RAG
def get_chatbot_response(user_query):
    # 1. T√¨m ki·∫øm trong Vector DB
    results = collection.query(query_texts=[user_query], n_results=3)
    
    # 2. X√¢y d·ª±ng ng·ªØ c·∫£nh (Context)
    context_text = ""
    for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
        context_text += f"\n[Ngu·ªìn: {meta['title']}]\n{doc}\nLink: {meta['url']}\n---"

    # 3. T·∫°o Prompt cho Gemini
    full_prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia h∆∞·ªõng d·∫´n th·ªß t·ª•c h√†nh ch√≠nh t·∫°i Vi·ªát Nam. 
H√£y s·ª≠ d·ª•ng th√¥ng tin d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c, l·ªãch s·ª±.
N·∫øu th√¥ng tin kh√¥ng c√≥ trong Context, h√£y n√≥i b·∫°n kh√¥ng bi·∫øt v√† khuy√™n ng∆∞·ªùi d√πng tra c·ª©u th√™m t·∫°i C·ªïng D·ªãch v·ª• c√¥ng.

CONTEXT:
{context_text}

C√ÇU H·ªéI: {user_query}
"""

    model = genai.GenerativeModel(GEMINI_MODEL)
    response = model.generate_content(full_prompt)
    return response.text

# √î nh·∫≠p li·ªáu chat
user_input = st.chat_input("H·ªèi v·ªÅ l√†m h·ªô chi·∫øu, c·∫•p ƒë·ªïi, l·ªá ph√≠...")

if user_input:
    # L∆∞u v√† hi·ªÉn th·ªã c√¢u h·ªèi ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # X·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ chatbot
    with st.chat_message("assistant"):
        with st.spinner("ƒêang tra c·ª©u d·ªØ li·ªáu..."):
            try:
                answer = get_chatbot_response(user_input)
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói: {str(e)}")

# Thanh b√™n (Sidebar)
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Emblem_of_Vietnam.svg/512px-Emblem_of_Vietnam.svg.png", width=80)
    st.header("Th√¥ng tin")
    st.info("Chatbot s·ª≠ d·ª•ng c√¥ng ngh·ªá RAG k·∫øt h·ª£p Google Gemini ƒë·ªÉ t∆∞ v·∫•n th·ªß t·ª•c h√†nh ch√≠nh.")
    if st.button("X√≥a l·ªãch s·ª≠ Chat"):
        st.session_state.messages = []
        st.rerun()
